<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Intercom & Music</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f5f5f5;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        .container {
            width: 100%;
            max-width: 600px;
            background-color: #ffffff;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            padding: 30px;
            box-sizing: border-box;
        }
        .title {
            font-size: 2.25rem; /* 36px */
            font-weight: 700;
            margin-bottom: 1.5rem; /* 24px */
            text-align: center;
            color: #1a202c; /* neutral-900 */
        }
        .section {
            background-color: #f9fafb; /* neutral-50 */
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            border: 1px solid #e5e7eb; /* neutral-200 */
        }
        .section-title {
            font-size: 1.5rem; /* 24px */
            font-weight: 600;
            margin-bottom: 15px;
            color: #2d3748; /* neutral-800 */
        }
        .input-field {
            width: 100%;
            padding: 10px 15px;
            border: 1px solid #d1d5db; /* neutral-300 */
            border-radius: 8px;
            margin-bottom: 15px;
            font-size: 1rem;
            color: #374151; /* neutral-700 */
        }
        .button-group {
            display: flex;
            justify-content: space-around;
            gap: 10px;
            margin-bottom: 15px;
        }
        .btn {
            padding: 12px 20px;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.1s ease;
            color: white;
            flex-grow: 1;
            text-align: center;
            border: none;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .btn:disabled {
            background-color: #cbd5e0; /* gray-400 */
            cursor: not-allowed;
            box-shadow: none;
        }
        .btn-green {
            background-color: #10b981; /* green-500 */
        }
        .btn-green:hover:not(:disabled) {
            background-color: #059669; /* green-600 */
            transform: translateY(-1px);
        }
        .btn-red {
            background-color: #ef4444; /* red-500 */
        }
        .btn-red:hover:not(:disabled) {
            background-color: #dc2626; /* red-600 */
            transform: translateY(-1px);
        }
        .btn-blue {
            background-color: #3b82f6; /* blue-500 */
        }
        .btn-blue:hover:not(:disabled) {
            background-color: #2563eb; /* blue-600 */
            transform: translateY(-1px);
        }
        .btn-orange {
            background-color: #f97316; /* orange-500 */
        }
        .btn-orange:hover:not(:disabled) {
            background-color: #ea580c; /* orange-600 */
            transform: translateY(-1px);
        }
        .btn-purple {
            background-color: #8b5cf6; /* purple-500 */
        }
        .btn-purple:hover:not(:disabled) {
            background: #7c3aed; /* purple-600 */
            transform: translateY(-1px);
        }
        .status-text {
            margin-top: 10px;
            font-size: 1rem;
            text-align: center;
            color: #4b5563; /* neutral-600 */
        }
        .connected-text {
            color: #10b981; /* green-500 */
            font-weight: 600;
        }
        .ducking-text {
            color: #f97316; /* orange-500 */
            font-weight: 600;
            text-align: center;
            margin-top: 5px;
        }
        .log-container {
            background-color: #e0e7eb; /* neutral-200 */
            border-radius: 10px;
            padding: 15px;
            height: 200px;
            overflow-y: scroll;
            margin-top: 20px;
            border: 1px solid #d1d5db; /* neutral-300 */
        }
        .log-title {
            font-size: 1.25rem; /* 20px */
            font-weight: 600;
            margin-bottom: 10px;
            color: #374151; /* neutral-700 */
        }
        .log-text {
            font-size: 0.875rem; /* 14px */
            color: #4b5563; /* neutral-600 */
            margin-bottom: 5px;
            line-height: 1.4;
        }
        .hidden {
            display: none;
        }
        .copy-area {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-top: 15px;
        }
        .copy-area textarea {
            flex-grow: 1;
            min-height: 80px;
            resize: vertical;
            padding: 10px;
            border: 1px solid #d1d5db;
            border-radius: 8px;
            font-size: 0.875rem;
            background-color: #f0f4f8;
            color: #374151;
        }
        .copy-btn {
            padding: 10px 15px;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            background-color: #6366f1; /* indigo-500 */
            color: white;
            border: none;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            transition: background-color 0.3s ease, transform 0.1s ease;
        }
        .copy-btn:hover {
            background-color: #4f46e5; /* indigo-600 */
            transform: translateY(-1px);
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="title">WebRTC Intercom & Music</h1>

        <div class="section">
            <h2 class="section-title">Connection Setup (Manual Signaling)</h2>
            <p class="status-text">Your Peer ID: <strong id="ownPeerId">Generating...</strong></p>
            <p class="status-text">Connection Status: <strong id="connectionStatus">Disconnected</strong></p>
            <div class="button-group">
                <button id="createOfferBtn" class="btn btn-green">Create Offer</button>
                <button id="pasteOfferBtn" class="btn btn-blue">Paste Offer</button>
            </div>
            <div class="button-group">
                <button id="pasteAnswerBtn" class="btn btn-blue">Paste Answer</button>
                <button id="pasteCandidateBtn" class="btn btn-orange">Paste ICE Candidate</button>
            </div>

            <div id="signalArea" class="hidden">
                <div class="copy-area">
                    <textarea id="signalDataTextarea" readonly placeholder="Signaling data will appear here."></textarea>
                    <button id="copySignalBtn" class="copy-btn">Copy</button>
                </div>
            </div>

            <p class="status-text mt-4">
                <span class="font-bold">Instructions:</span>
                Open this page in two separate browser tabs/devices.
                <br>1. On Device A, click "Create Offer". Copy the text that appears.
                <br>2. On Device B, click "Paste Offer" and paste the text from Device A. Device B will then "Create Answer". Copy this answer text.
                <br>3. On Device A, click "Paste Answer" and paste the answer text from Device B.
                <br>4. During this process, both devices will generate ICE Candidates (network info). Paste any generated ICE candidates into the other device using "Paste ICE Candidate".
            </p>
        </div>

        <div class="section">
            <h2 class="section-title">Intercom Control</h2>
            <button id="toggleIntercomBtn" class="btn btn-green">Start Intercom (Mic On)</button>
            <p class="status-text">Intercom: <span id="intercomStatus">OFF</span></p>
        </div>

        <div class="section">
            <h2 class="section-title">Music Control</h2>
            <button id="toggleIndividualMusicBtn" class="btn btn-blue">Toggle My Music (Simulated)</button>
            <p class="status-text">My Music: <span id="individualMusicStatus">OFF</span></p>

            <div style="margin-top: 15px;">
                <button id="toggleSharedMusicBtn" class="btn btn-purple">Toggle Shared Music</button>
                <input type="range" id="sharedMusicVolumeSlider" min="0" max="1" step="0.01" value="1" class="w-full mt-2">
            </div>
            <p class="status-text">Shared Music: <span id="sharedMusicStatus">OFF</span></p>
            <p id="musicDuckingStatus" class="ducking-text hidden">Music Volume Ducked (Intercom Active)</p>
        </div>

        <div class="log-container">
            <h2 class="log-title">Activity Log:</h2>
            <div id="logScroll"></div>
        </div>
        <audio id="remoteAudio" autoplay></audio> <!-- For playing remote intercom audio -->
    </div>

    <script>
        // --- DOM Elements ---
        const ownPeerIdSpan = document.getElementById('ownPeerId');
        const connectionStatusSpan = document.getElementById('connectionStatus');
        const createOfferBtn = document.getElementById('createOfferBtn');
        const pasteOfferBtn = document.getElementById('pasteOfferBtn');
        const pasteAnswerBtn = document.getElementById('pasteAnswerBtn');
        const pasteCandidateBtn = document.getElementById('pasteCandidateBtn');
        const toggleIntercomBtn = document.getElementById('toggleIntercomBtn');
        const intercomStatusSpan = document.getElementById('intercomStatus');
        const toggleIndividualMusicBtn = document.getElementById('toggleIndividualMusicBtn');
        const individualMusicStatusSpan = document.getElementById('individualMusicStatus');
        const toggleSharedMusicBtn = document.getElementById('toggleSharedMusicBtn');
        const sharedMusicStatusSpan = document.getElementById('sharedMusicStatus');
        const musicDuckingStatusP = document.getElementById('musicDuckingStatus');
        const logScroll = document.getElementById('logScroll');
        const remoteAudioElement = document.getElementById('remoteAudio');
        const sharedMusicVolumeSlider = document.getElementById('sharedMusicVolumeSlider');

        const signalArea = document.getElementById('signalArea');
        const signalDataTextarea = document.getElementById('signalDataTextarea');
        const copySignalBtn = document.getElementById('copySignalBtn');


        // --- Global WebRTC Variables ---
        let peerConnection; // RTCPeerConnection object
        let localStream;    // Local media stream (microphone)
        let dataChannel;    // WebRTC DataChannel for music control
        let ownPeerId = generateRandomId();
        let connectionState = 'disconnected'; // WebRTC connection state

        // --- Web Audio API Variables ---
        let audioContext;
        let micSource;
        let remoteMicSource;
        let individualMusicSource; // Placeholder for individual music
        let sharedMusicAudioBuffer; // Loaded audio buffer for shared music
        let sharedMusicSource; // AudioBufferSourceNode for shared music playback
        let sharedMusicStartTime = 0;
        let sharedMusicOffset = 0;
        let isSharedMusicPlaying = false;
        let sharedMusicGainNode; // For ducking shared music
        let localMicGainNode; // For controlling local mic output if needed

        // --- Mock Audio Manager (now interacts with Web Audio API) ---
        class AudioManager {
            constructor() {
                this.isIntercomActive = false; // Is the mic actively sending intercom audio?
                this.isIndividualMusicPlaying = false; // Is local music playing?
                this.intercomVolume = 1.0;
                this.musicVolume = 1.0; // Individual music volume (conceptual)
            }

            // Initializes the Web Audio API context and nodes
            async initAudioContext() {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    appendLog('AudioContext created.');

                    // Create gain nodes for control and ducking
                    sharedMusicGainNode = audioContext.createGain();
                    // Connect shared music gain to destination (speakers)
                    sharedMusicGainNode.connect(audioContext.destination);
                    sharedMusicVolumeSlider.value = sharedMusicGainNode.gain.value;

                    // Load shared music audio file
                    try {
                        // Using a royalty-free sound effect as a placeholder
                        const audioUrl = 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3'; // Example MP3
                        const response = await fetch(audioUrl);
                        const arrayBuffer = await response.arrayBuffer();
                        sharedMusicAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        appendLog('Shared music audio loaded.');
                    } catch (error) {
                        appendLog(`Error loading shared music: ${error}`);
                    }
                }
            }

            // Sets up local microphone audio for WebRTC and local monitoring (optional)
            async setupLocalMicAudio() {
                if (localStream && audioContext && !micSource) {
                    micSource = audioContext.createMediaStreamSource(localStream);
                    localMicGainNode = audioContext.createGain(); // For controlling local mic output volume
                    micSource.connect(localMicGainNode);
                    localMicGainNode.connect(audioContext.destination); // Connect to speakers for local monitoring
                    localMicGainNode.gain.value = 0; // Start with local mic monitoring off
                    appendLog('Local mic audio source connected to AudioContext.');
                }
            }

            // Handles incoming remote audio stream
            setupRemoteMicAudio(stream) {
                if (audioContext && stream && !remoteMicSource) {
                    remoteMicSource = audioContext.createMediaStreamSource(stream);
                    remoteMicSource.connect(audioContext.destination); // Connect remote audio to speakers
                    appendLog('Remote mic audio source connected to AudioContext.');
                }
            }

            // Toggles actual shared music playback
            toggleSharedMusicPlayback(shouldPlay, initialOffset = 0) {
                if (!sharedMusicAudioBuffer) {
                    appendLog('Shared music not loaded yet.');
                    return;
                }

                if (shouldPlay && !isSharedMusicPlaying) {
                    if (sharedMusicSource) { // If a previous source exists, stop it
                        sharedMusicSource.stop();
                        sharedMusicSource.disconnect();
                    }
                    sharedMusicSource = audioContext.createBufferSource();
                    sharedMusicSource.buffer = sharedMusicAudioBuffer;
                    sharedMusicSource.connect(sharedMusicGainNode); // Connect via gain node
                    sharedMusicSource.loop = true; // Loop the music
                    sharedMusicSource.start(0, initialOffset);
                    sharedMusicStartTime = audioContext.currentTime - initialOffset;
                    isSharedMusicPlaying = true;
                    appendLog(`Shared music started from offset: ${initialOffset.toFixed(2)}s`);
                } else if (!shouldPlay && isSharedMusicPlaying) {
                    if (sharedMusicSource) {
                        sharedMusicSource.stop();
                        sharedMusicSource.disconnect();
                        sharedMusicSource = null;
                        sharedMusicOffset = audioContext.currentTime - sharedMusicStartTime; // Save current position
                    }
                    isSharedMusicPlaying = false;
                    appendLog('Shared music paused.');
                }
                this._manageAudioLevels();
                updateUI();
            }

            // This is the core logic for mixing and ducking using GainNodes
            _manageAudioLevels() {
                // If intercom is active (mic enabled), duck music volume.
                const targetMusicVolume = this.isIntercomActive ? 0.3 : 1.0;

                // Apply ducking to shared music
                if (sharedMusicGainNode) {
                    sharedMusicGainNode.gain.setTargetAtTime(targetMusicVolume * sharedMusicVolumeSlider.value, audioContext.currentTime, 0.1); // Smooth transition
                    this.musicVolume = targetMusicVolume; // Update conceptual volume
                    this.sharedMusicVolume = targetMusicVolume; // Update conceptual volume
                }

                // If you had individual music playing via Web Audio API, you'd apply ducking here too
                // For now, individual music is simulated, so its volume is conceptual.

                appendLog(`Current audio levels: Intercom=${this.intercomVolume}, Individual Music=${this.musicVolume} (conceptual), Shared Music=${sharedMusicGainNode ? sharedMusicGainNode.gain.value : 'N/A'}`);
                this.updateMusicDuckingUI();
            }

            // Toggles sending local mic audio (triggers ducking)
            toggleIntercomMic(enable) {
                if (localStream) {
                    localStream.getAudioTracks().forEach(track => {
                        track.enabled = enable;
                        this.isIntercomActive = enable;
                    });
                    this._manageAudioLevels(); // Re-evaluate ducking
                    updateUI();
                    appendLog(`Intercom mic ${enable ? 'enabled' : 'disabled'}.`);
                } else {
                    appendLog('Microphone stream not available to toggle.');
                }
            }

            // Controls the master volume of shared music (via slider)
            setSharedMusicMasterVolume(volume) {
                if (sharedMusicGainNode) {
                    sharedMusicGainNode.gain.value = volume;
                    this._manageAudioLevels(); // Re-apply ducking on top of new master volume
                    appendLog(`Shared music master volume set to ${volume.toFixed(2)}`);
                }
            }
        }
        const audioManager = new AudioManager();


        // --- Utility Functions ---
        function generateRandomId() {
            return Math.random().toString(36).substring(2, 9).toUpperCase();
        }

        function appendLog(message) {
            const logEntry = document.createElement('p');
            logEntry.textContent = message;
            logEntry.classList.add('log-text');
            logScroll.prepend(logEntry); // Add new logs to the top
            // Limit log entries to prevent excessive DOM elements
            if (logScroll.children.length > 50) {
                logScroll.removeChild(logScroll.lastChild);
            }
        }

        function showSignalData(data) {
            signalDataTextarea.value = JSON.stringify(data);
            signalArea.classList.remove('hidden');
        }

        function hideSignalData() {
            signalDataTextarea.value = '';
            signalArea.classList.add('hidden');
        }

        copySignalBtn.addEventListener('click', () => {
            document.execCommand('copy'); // Use deprecated but reliable execCommand for cross-browser clipboard access in iframes
            appendLog('Signaling data copied to clipboard!');
        });
        // Add listener for copy button to actually copy the text from the textarea
        signalDataTextarea.addEventListener('copy', (event) => {
            event.clipboardData.setData('text/plain', signalDataTextarea.value);
            event.preventDefault();
        });


        // --- WebRTC Functions ---

        // 1. Get Local Media Stream (Mic)
        async function getLocalStream() {
            try {
                // Request microphone permission
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: true,
                    video: false // Only audio for intercom
                });
                localStream = stream;
                await audioManager.setupLocalMicAudio(); // Connect mic to AudioContext
                appendLog('Microphone access granted. Local audio stream obtained.');
                return stream;
            } catch (error) {
                appendLog(`Error accessing microphone: ${error.name} - ${error.message}`);
                // Provide a user-friendly message for permission denied
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    alert('Microphone access is required for the intercom. Please enable it in your browser settings.');
                }
                return null;
            }
        }

        // 2. Initialize Peer Connection
        async function initPeerConnection(isCreator) {
            if (peerConnection && peerConnection.connectionState !== 'closed') {
                peerConnection.close();
                appendLog('Previous peer connection closed.');
            }

            const configuration = {
                iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] // Google's public STUN server
            };
            peerConnection = new RTCPeerConnection(configuration);
            appendLog('RTCPeerConnection created.');

            // Create DataChannel for music control
            if (isCreator) {
                dataChannel = peerConnection.createDataChannel("musicControl");
                dataChannel.onopen = (event) => {
                    appendLog('Data Channel opened!');
                    updateUI();
                };
                dataChannel.onmessage = (event) => handleMusicControlMessage(event.data);
                dataChannel.onclose = (event) => {
                    appendLog('Data Channel closed.');
                    updateUI();
                };
            } else {
                peerConnection.ondatachannel = (event) => {
                    dataChannel = event.channel;
                    dataChannel.onopen = (event) => {
                        appendLog('Data Channel opened!');
                        updateUI();
                    };
                    dataChannel.onmessage = (event) => handleMusicControlMessage(event.data);
                    dataChannel.onclose = (event) => {
                        appendLog('Data Channel closed.');
                        updateUI();
                    };
                };
            }


            // Add local audio track to the connection
            if (!localStream) {
                localStream = await getLocalStream();
                if (!localStream) {
                    appendLog('Cannot proceed without local audio stream. Connection aborted.');
                    return;
                }
            }
            localStream.getTracks().forEach(track => peerConnection.addTrack(track, localStream));
            appendLog('Local audio track added to PeerConnection.');

            // Event handler for ICE candidates (network info)
            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    appendLog('Generated ICE Candidate. Copy this and paste into the other browser.');
                    showSignalData(event.candidate);
                }
            };

            // Event handler for remote stream (audio from other peer)
            peerConnection.ontrack = (event) => {
                if (event.streams && event.streams[0]) {
                    appendLog('Remote audio stream received!');
                    remoteAudioElement.srcObject = event.streams[0];
                    remoteAudioElement.play().catch(e => appendLog(`Error playing remote audio: ${e}`));
                    // Also connect remote audio to Web Audio API for potential mixing/processing
                    audioManager.setupRemoteMicAudio(event.streams[0]);
                    connectionState = 'connected';
                    updateUI();
                }
            };

            // Event handler for connection state changes
            peerConnection.onconnectionstatechange = () => {
                connectionState = peerConnection.connectionState;
                appendLog(`WebRTC connection state: ${connectionState}`);
                updateUI();
                if (connectionState === 'connected') {
                    appendLog('Peer connection established successfully!');
                    hideSignalData(); // Hide signaling area once connected
                } else if (connectionState === 'failed' || connectionState === 'disconnected' || connectionState === 'closed') {
                    appendLog('WebRTC connection failed, disconnected, or closed. Please try re-initiating the connection.');
                    remoteAudioElement.srcObject = null; // Stop remote audio
                    hideSignalData();
                }
            };

            // If this device is creating the offer, proceed to create it
            if (isCreator) {
                createOffer();
            }
        }

        // 3. Create Offer (for the calling party)
        async function createOffer() {
            if (!peerConnection || peerConnection.signalingState === 'closed') {
                await initPeerConnection(true); // Re-initialize if not ready
                return;
            }
            try {
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);
                appendLog('Offer created. Copy this and paste into the other browser.');
                showSignalData(offer);
            } catch (error) {
                appendLog(`Error creating offer: ${error}`);
            }
        }

        // 4. Paste Offer (for the answering party)
        async function pasteOffer() {
            if (!peerConnection || peerConnection.signalingState === 'closed') {
                await initPeerConnection(false); // Initialize without creating offer
                await new Promise(r => setTimeout(r, 500)); // Give a small delay for init
            }

            // Use prompt for pasting input. The textarea is for displaying generated data.
            const offerText = prompt('Paste WebRTC Offer here:');
            if (offerText) {
                try {
                    const offer = JSON.parse(offerText);
                    await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
                    appendLog('Offer pasted and set as remote description.');
                    createAnswer(); // Automatically create answer after setting remote offer
                } catch (error) {
                    appendLog(`Error processing offer: ${error}`);
                    alert('Invalid WebRTC Offer. Please check the copied text.');
                }
            } else {
                appendLog('No offer pasted.');
                hideSignalData(); // Hide if nothing was pasted
            }
        }

        // 5. Create Answer (for the answering party)
        async function createAnswer() {
            if (!peerConnection || !peerConnection.remoteDescription || peerConnection.signalingState === 'closed') {
                appendLog('Peer connection not ready to create answer (no remote offer set or connection closed).');
                return;
            }
            try {
                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                appendLog('Answer created. Copy this and paste into the other browser.');
                showSignalData(answer);
            } catch (error) {
                appendLog(`Error creating answer: ${error}`);
            }
        }

        // 6. Paste Answer (for the calling party)
        async function pasteAnswer() {
            // Use prompt for pasting input. The textarea is for displaying generated data.
            const answerText = prompt('Paste WebRTC Answer here:');
            if (answerText) {
                try {
                    const answer = JSON.parse(answerText);
                    await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
                    appendLog('Answer pasted and set as remote description.');
                } catch (error) {
                    appendLog(`Error processing answer: ${error}`);
                    alert('Invalid WebRTC Answer. Please check the copied text.');
                }
            } else {
                appendLog('No answer pasted.');
                hideSignalData(); // Hide if nothing was pasted
            }
        }

        // 7. Paste ICE Candidate
        async function pasteCandidate() {
            // Use prompt for pasting input. The textarea is for displaying generated data.
            const candidateText = prompt('Paste WebRTC ICE Candidate here:');
            if (candidateText) {
                try {
                    const candidate = JSON.parse(candidateText);
                    await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
                    appendLog('ICE Candidate added.');
                } catch (error) {
                    appendLog(`Error processing ICE Candidate: ${error}`);
                    alert('Invalid ICE Candidate. Please check the copied text.');
                }
            } else {
                appendLog('No ICE Candidate pasted.');
                hideSignalData(); // Hide if nothing was pasted
            }
        }

        // --- Data Channel Handlers for Music Control ---
        function sendMusicControlMessage(type, value) {
            if (dataChannel && dataChannel.readyState === 'open') {
                const message = JSON.stringify({ type, value, timestamp: audioContext.currentTime });
                dataChannel.send(message);
                appendLog(`Sent music control: ${message}`);
            } else {
                appendLog('Data Channel not open. Cannot send music control messages.');
            }
        }

        function handleMusicControlMessage(message) {
            try {
                const { type, value, timestamp } = JSON.parse(message);
                appendLog(`Received music control: Type=${type}, Value=${value}, Timestamp=${timestamp}`);
                switch (type) {
                    case 'play':
                        // Calculate offset for synchronized playback
                        const receivedTime = timestamp;
                        const localTime = audioContext.currentTime;
                        const offset = (localTime - receivedTime + value) % sharedMusicAudioBuffer.duration;
                        audioManager.toggleSharedMusicPlayback(true, offset);
                        break;
                    case 'pause':
                        audioManager.toggleSharedMusicPlayback(false);
                        break;
                    case 'volume':
                        sharedMusicVolumeSlider.value = value;
                        audioManager.setSharedMusicMasterVolume(parseFloat(value));
                        break;
                    // Add other control types if needed (e.g., seek, next song)
                }
            } catch (error) {
                appendLog(`Error parsing music control message: ${error}`);
            }
        }

        // --- Event Listeners ---
        createOfferBtn.addEventListener('click', createOffer);
        pasteOfferBtn.addEventListener('click', pasteOffer);
        pasteAnswerBtn.addEventListener('click', pasteAnswer);
        pasteCandidateBtn.addEventListener('click', pasteCandidate);

        copySignalBtn.addEventListener('click', () => {
            signalDataTextarea.select();
            document.execCommand('copy');
            appendLog('Signaling data copied to clipboard!');
            hideSignalData(); // Hide after copying
        });

        // Intercom toggle button
        toggleIntercomBtn.addEventListener('click', () => {
            if (peerConnection && peerConnection.connectionState === 'connected') {
                const enable = !audioManager.isIntercomActive;
                audioManager.toggleIntercomMic(enable);
            } else {
                appendLog('Please establish a WebRTC connection first to use intercom.');
            }
        });

        // Individual Music toggle button
        toggleIndividualMusicBtn.addEventListener('click', () => {
            audioManager.toggleIndividualMusic();
            updateUI();
        });

        // Shared Music toggle button
        toggleSharedMusicBtn.addEventListener('click', () => {
            if (peerConnection && peerConnection.connectionState === 'connected') {
                const shouldPlay = !isSharedMusicPlaying;
                if (shouldPlay) {
                    sendMusicControlMessage('play', sharedMusicOffset); // Send current offset to sync
                } else {
                    sendMusicControlMessage('pause', null);
                }
                // Also toggle locally
                audioManager.toggleSharedMusicPlayback(shouldPlay, sharedMusicOffset);
            } else {
                appendLog('Please establish a WebRTC connection first to share music.');
            }
        });

        // Shared Music Volume Slider
        sharedMusicVolumeSlider.addEventListener('input', (event) => {
            const volume = parseFloat(event.target.value);
            audioManager.setSharedMusicMasterVolume(volume);
            if (dataChannel && dataChannel.readyState === 'open') {
                sendMusicControlMessage('volume', volume); // Sync volume with other peer
            }
        });

        // --- Initial Setup on Page Load ---
        window.onload = async () => {
            ownPeerId = generateRandomId();
            ownPeerIdSpan.textContent = ownPeerId;
            updateUI();
            appendLog('Page loaded. Initializing AudioContext and loading music...');
            await audioManager.initAudioContext(); // Initialize Web Audio API
            appendLog('Please grant microphone permission when prompted for intercom.');
            await getLocalStream(); // Attempt to get mic access early
        };

        // UI update function to keep statuses current
        function updateUI() {
            connectionStatusSpan.textContent = connectionState.toUpperCase();
            connectionStatusSpan.className = connectionState === 'connected' ? 'connected-text' : '';

            const isConnectedAndDataChannelOpen = connectionState === 'connected' && dataChannel && dataChannel.readyState === 'open';

            toggleIntercomBtn.disabled = !isConnectedAndDataChannelOpen;
            toggleSharedMusicBtn.disabled = !isConnectedAndDataChannelOpen;
            sharedMusicVolumeSlider.disabled = !isConnectedAndDataChannelOpen;

            intercomStatusSpan.textContent = audioManager.isIntercomActive ? 'ACTIVE' : 'OFF';
            individualMusicStatusSpan.textContent = audioManager.isIndividualMusicPlaying ? 'PLAYING' : 'OFF';
            sharedMusicStatusSpan.textContent = isSharedMusicPlaying ? 'PLAYING' : 'OFF'; // Use the global isSharedMusicPlaying

            toggleIntercomBtn.textContent = audioManager.isIntercomActive ? 'Stop Intercom (Mic Off)' : 'Start Intercom (Mic On)';
            toggleIntercomBtn.classList.toggle('btn-red', audioManager.isIntercomActive);
            toggleIntercomBtn.classList.toggle('btn-green', !audioManager.isIntercomActive);

            toggleIndividualMusicBtn.textContent = audioManager.isIndividualMusicPlaying ? 'Stop My Music' : 'Toggle My Music (Simulated)';
            toggleIndividualMusicBtn.classList.toggle('btn-orange', audioManager.isIndividualMusicPlaying);
            toggleIndividualMusicBtn.classList.toggle('btn-blue', !audioManager.isIndividualMusicPlaying);

            toggleSharedMusicBtn.textContent = isSharedMusicPlaying ? 'Stop Shared Music' : 'Toggle Shared Music';
            toggleSharedMusicBtn.classList.toggle('btn-orange', isSharedMusicPlaying);
            toggleSharedMusicBtn.classList.toggle('btn-purple', !isSharedMusicPlaying);

            audioManager.updateMusicDuckingUI();
        }
    </script>
</body>
</html>
